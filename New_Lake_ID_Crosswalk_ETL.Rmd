---
title: "LAGOS Lake Link: Creation"
output:
  html_notebook
---

```{r setup, include=FALSE}
library(tidyverse)
library(sf)
library(dataRetrieval) # WQP web service library
library(XML)
library(leaflet)
library(mapview)
knitr::opts_chunk$set(message=FALSE)

NAD83 = '+init=epsg:4269'
NAD27 = '+init=epsg:4267'
WGS84 = '+init=epsg:4326'
WGS72 = '+init=epsg:4322'
ALBERS_USGS = '+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'
USGS_ATTR <- paste0("<a href='https://www.usgs.gov/'>",
              "U.S. Geological Survey</a> | ",
              "<a href='https://www.usgs.gov/laws/policies_notices.html'>",
              "Policies</a>")
NHD_URL <- 'https://hydro.nationalmap.gov/arcgis/services/nhd/MapServer/WMSServer'

list_shared_words <- function(string1, string2, exclude_lake_words = TRUE) {
  exclusion_set <- c('LAKE', 'POND', 'RESERVOIR', 'DAM')
  words1 <- string1 %>%
    toupper() %>%
    strsplit("\\s+")
  words2 <- string2 %>%
    toupper() %>%
    strsplit("\\s+")
  if (exclude_lake_words == TRUE) {
    words1 <- sapply(words1, function(x) setdiff(x, exclusion_set))
    words2 <- sapply(words2, function(x) setdiff(x, exclusion_set))
  }
  intersection <- mapply(intersect, words1, words2, USE.NAMES = FALSE)
  
  format_result <- function(x) {
    if (length(x) > 1) {
      result <- paste(x, collapse = "; ")
    }
    else {
      if (identical(x, character(0))) {
        result <- as.character(NA)
      }
      else {
        if (is.na(x)) {
          result <- as.character(NA)
        }
        else {
          result <- paste(x, collapse = "; ")
        }
      }
    }
  }
  
  result <- sapply(intersection, format_result)
  return(result)
}
```
The purpose of this document is to delineate the processing steps used to join lake identifiers from 5 data products into a single lake identifier table called LAGOS Lake Link (**working name**).
# Definitions in this document
"Lake": Permanent lake or reservoir.

# What is LAGOS Lake Link?
LAGOS Lake Link is a tabular dataset (a crosswalk table) that can be used to connect one lake-related dataset to another for many common lake datasets. Several lake datasets are in common use on their own or as a base for scientific data products and LAGOS Lake Link is intended to make it easier to combine lake-related data between multiple sources. The table can be searched to find identifiers and location for a particular lake, or it can be used in data join operations to convert identifiers en masse. 

There are two main spatial representations used for lake locations: polygons, used in the various NHD products (National Hydrography Dataset), and points, used in other national datasets. In addition to the spatial representations, there are a variety of identifiers found among the datasets portraying lakes in the United States: state agency IDs, Water Quality Portal MonitoringLocationIdentifier (from systems such as STORET and NWIS), NHDPlusV2 COMID, NHD ReachCode, NHD-HR Permanent_Identifier, GNIS_ID. Finally, lakes are sometimes named and can be identified by their name alone if it unique, or their name and geographic context.

There are several obstacles to reliably identifying common lakes between these datasets: 

* Inadequate location accuracy
* Inconsistent classification of waterbodies as lakes vs. another type
* Inconsistent delineation of lake extent
* Conflicting names
* Unaccounted change in identifiers within a dataset
* Unsynchronized update patterns between datasets 

When I say "inadequate" or "inconsistent" here, I am describing the quality relative to my specific task of connecting datasets. Independently, these datasets have high standards for data quality--but two datasets may use, for example, different definitions of the lake entity, and that is where problems arise for my task.

# Entity-relationship diagram
```{r, fig.cap = "\\label{fig:figs}ERD model for LAGOS Lake Link crosswalk table"}
knitr::include_graphics('./images/ERD_as_is.PNG')
```

# Processing Pipeline
5 main datasets will be introduced to create the crosswalk: LAGOS (US), GNIS, WQP, NHDPlusV2 (medium-resolution), and LAGOS-NE. For each dataset, the workflow is as follows: 

1) **Import.** Modify fields and prepare the data frame for later work.
2) **Filter.** We focus here on lakes and reservoirs in the continental United States. In order to preserve this focus, categories of entities that are less likely to represent one of these features are pruned away during this step, even if those categories sometimes connect to a LAGOS-US lake. The crosswalk only includes relationships if they ultimately connect back to a LAGOS-US lake. For example--even though you can use this table to walk between WQP sites and NHDPlusV2 lakes, the relationship is not comprehensive because lakes not found in LAGOS-US are missing.
3) **Convert** between spatial and non-spatial data formats, as needed. Spatial formats are projected to the USGS Albers Conic Equal Area projection for consistency.
4) **Select** only the necessary columns for the upcoming work.
5) **Join LAGOS-US** to each other dataset, individually. This step may include spatial joins, joins on common identifiers. After joining, identifying fields may be flattened into a single concatenated field or coalesced.
6) **Select again** again as needed before the final join.

```{r}
knitr::include_graphics('./images/Processing_flow.PNG')
```

Finally, the results of the multiple joins in step 4 will be merged into a single crosswalk table with only the necessary fields remaining.

# LAGOS-US
The LAGOS-US lake population is the focal dataset of the LAGOS Lake Link crosswalk (top center, Figure \ref{fig:figs}). We will connect all other datasets to this one in the crosswalk. Lakes will only This dataset is a subset of the NHD High Resolution NHDWaterbody layers (see "Filter" section for details) representing permanent, non-artificial LakePond and Reservoir waterbodies. Currently, LAGOS-US is under development and while the lake polygon dataset is completed, much of the database remains to be built in 2018 and 2019.

The primary identifier for lakes in this dataset is **lagoslakeid**. A secondary unique identifier is named **nhdid** in the "locus" table, which corresponds to the **Permanent_Identifier** in the NHD and in the GIS layer imported here.

## Import
We'll import the GIS polygon layer prepared for LAGOS-US.
```{r read-lagos, cache=TRUE}
# lagos_sf <- st_read('D:/Continental_Limnology/Data_Working/LAGOS_US_Predecessors.gdb', 'NHDWaterbody_LAGOS', stringsAsFactors = FALSE) %>%
#   st_zm(drop=TRUE) %>%
#   mutate(GNIS_ID = as.integer(GNIS_ID)) %>%
#   st_transform(ALBERS_USGS) # no actual change, just proj4string housekeeping.
# save(lagos_sf, file = './rdata/lagos_sf.RData')
load('./rdata/lagos_sf.RData')
glimpse(lagos_sf)
```

## Filter
The LAGOS-US dataset has already been filtered from the source dataset of all NHDWaterbody features to generate the final target lake population. The code is not included but the processing rules are summarized below.

Criteria for selecting NHD lake polygons for inclusion in LAGOS-US were as follows. Included lakes must:

* Be derived from snapshots of the NHD staged by subregion taken 2016-12-15, 2016-12-16, 2017-01-03 (HUC4 1019), 2017-01-03 (HUC4 0309, 1004, 1804).
* Not be an exact duplicate of another NHD lake polygon.
* If a duplicate of another lake except for FDate and Shape, then the lake retained must have the most recent FDate (feature edit date).
* Intersect the LAGOS-US contiguous U.S. layer (48 states plus D.C., TIGER/Line data).
* Be represented as simple features--we densified several features with only 2 vertices using 10 m as the maximum deviation for each vertex in order to "repair" their representation to match the majority and the standard.
* Not be Great Lakes or the portion of Lake St. Clair (MI/ON) that is in Canada.
* Have an AreaSqKm > 0.009 (AreqSqKm field included in original NHDWaterbody).
* Have a polygon area greater than or equal to 1 hectare (calculated during LAGOS-US processing and measured in the Albers USGS Conic projection). The calculated area occasionally does not match the area in square kilometers provided by NHD.
* Be assigned one of the following Feature Codes representing permanent water bodies and non-artificial water bodies:
    + 39000,39004,39009,39010,39011,39012 (lakes)
    + 43600,43613,43615,43617,43618,43619,43621 (reservoirs)
* One lake in Mexico was removed (Permanent_Identifier = 'e05e57b5-d29f-4e1e-8369-73e55f8be9df') after independent verification of the lake processing workflow revealed a single discrepancy due to slight variations in order of when data projection was performed.  

The number of LAGOS-US lakes after filtering is `r nrow(lagos_sf)`.

## Convert and Select

```{r convert-lagos, cache = TRUE}
lagos <- lagos_sf %>%
  select(lagoslakeid, 
         Permanent_Identifier, 
         GNIS_ID, 
         GNIS_Name, 
         ReachCode, 
         STATE, 
         AreaSqKm, 
         FDate,
         LAGOS_CountyName = NAMELSAD,
         LAGOS_CountyFIPS = FIPS)

lagos_centroid <- lagos_sf %>%
  st_centroid() %>%
  st_transform(NAD83) %>%
  mutate(LAGOS_LatitudeNAD83 = st_coordinates(.)[,'Y'], 
         LAGOS_LongitudeNAD83 = st_coordinates(.)[,'X']) %>%
  select(lagoslakeid, LAGOS_LatitudeNAD83, LAGOS_LongitudeNAD83)

lagos_df <- lagos %>% st_set_geometry(NULL)
```

# GNIS (Geographic Names Information System)
The GNIS dataset contains place names for a variety of geographic features, including lakes, in the United States. Locations are represented as latitude/longitude pairs. Most NHD lakes already have a GNIS name assigned, but in some cases where lakes had multiple names, they were not assigned a name in the NHD. To populate the lake name as fully as possible, we searched the GNIS dataset to both add missing names where available and to document lakes with multiple names, which we then retain in LAGOS-US.

## Import
```{r read-gnis, cache=TRUE, include = FALSE}
gnis_link <- 'https://geonames.usgs.gov/docs/stategaz/NationalFile_20180201.zip' # changes with updates
tf <- tempfile()
download.file(gnis_link, tf)

?unzip
gnis_orig <- read_delim(unzip(tf), '|', quote = "")
# Remove the byte order mark from first column name
names(gnis_orig)[1] <- "FEATURE_ID"
```

Glimpse the original GNIS table.
```{r}
glimpse(gnis_orig)
```


## Filter
Included GNIS sites must:

* Be within one of the 48 contiguous states or D.C (FIPS code match)
* Be within the rough bounding box of the U.S. (eliminates a few spurious locations)
* Be assigned the Lake or Reservoir Feature Class. These feature classes aggregate a variety of feature names such as Lake, Lakes, Reservoir, Pond, Tank, Slough, Millpond, etc. _A prior analysis showed that nearly all GNIS names already assigned in the NHD correspond to one of these two classes, with minor use of Swamp, Flat, and rare use of a smattering of other feature classes. We choose to focus the crosswalk on the most relevant locations rather than conserve all possible links._
* Not be assigned a "historical" site name. Such names are spatially coincident with the current name.

```{r filter-gnis}
# Get a list of state codes in order to filter for only CONUS (48 states plus DC)
fips_filter <- read_delim('https://www2.census.gov/geo/docs/reference/state.txt', '|') %>%
  filter(!(STATE %in% c('02', '15') | STATE > '56')) %>% 
  select(STUSAB)

gnis_filtered <- gnis_orig %>% 
  inner_join(fips_filter, by = c("STATE_ALPHA" = "STUSAB")) %>%
  filter(PRIM_LONG_DEC < -67 & PRIM_LONG_DEC > -125 & PRIM_LAT_DEC < 50 & PRIM_LAT_DEC > 24) %>%
  filter(FEATURE_CLASS %in% c('Lake', 'Reservoir')) %>%
  filter(!grepl(("historical"), FEATURE_NAME))
```
The number of GNIS sites for U.S. lakes is `r nrow(gnis_filtered)`.

## Convert
According to the [metadata](https://geonames.usgs.gov/domestic/faqs.htm), the coordinates use the NAD83 datum.
```{r convert-gnis}
gnis_sf <- gnis_filtered %>% 
  st_as_sf(coords = c("PRIM_LONG_DEC", "PRIM_LAT_DEC")) %>% 
  st_set_crs(NAD83) %>%
  st_transform(ALBERS_USGS)
```

## Select
```{r select-gnis}
gnis <- gnis_sf %>%
  select(FEATURE_ID, FEATURE_NAME, FEATURE_CLASS)
```

## Join LAGOS-US
First, join LAGOS-US to GNIS based on the shared GNIS_ID.
```{r join-gnis1}
lagos_gnis_1 <- gnis %>%
  st_set_geometry(NULL) %>%
  right_join(lagos, by = c("FEATURE_ID" = "GNIS_ID")) %>%
  rename(
    GNIS_FeatureClass = FEATURE_CLASS
    )
```


GNIS Names contained by the polygon are assigned to the lake. A new column, "LAGOS Lake Name" is created and multiple names for a lake are separated by semi-colons. This will eliminate the 1:many relationship created in the join.

```{r join-gnis2, cache = TRUE}
lagos_gnis_2 <- lagos %>%
  st_join(gnis)

new_names <- lagos_gnis_2 %>%
  st_set_geometry(NULL) %>%
  # the following is long-winded way to say put names together with semi-colon
  # feels like this should be easier code...
  distinct(lagoslakeid, GNIS_Name, FEATURE_NAME) %>%
  filter((!is.na(FEATURE_NAME) &  is.na(GNIS_Name)) | GNIS_Name != FEATURE_NAME) %>%
  group_by(lagoslakeid, GNIS_Name) %>%
  summarise(partial_new_name = paste(FEATURE_NAME, collapse = "; ")) %>%
  ungroup() %>%
  unite(LAGOS_LakeName, GNIS_Name, partial_new_name, sep = "; ") %>%
  mutate(LAGOS_LakeName = gsub('NA;', '', LAGOS_LakeName))

lagos_gnis_3 <- lagos %>%
  left_join(new_names, by = "lagoslakeid") %>%
  mutate(LAGOS_LakeName = if_else(is.na(LAGOS_LakeName), GNIS_Name, LAGOS_LakeName))
```

## Select again
```{r select2-gnis}
lagos_gnis <- lagos_gnis_3 %>%
  st_set_geometry(NULL) %>%
  select(lagoslakeid, Permanent_Identifier, GNIS_ID, GNIS_Name, ReachCode, STATE, LAGOS_LakeName, AreaSqKm)
```

# WQP (Water Quality Portal--STORET, NWIS, and more)
The WQP API allows queries of all water quality monitoring sites that are submitted to major national databases. Sites are described with identifiers, coordinates, and names, but are not definitively linked to any polygon representation of lakes to our knowledge. The goal here is to match the WQP identifiers with lakes in LAGOS-US.

## Import
Glimpse the original WQP table.
```{r read-wqp, cache = TRUE, message = FALSE, warning = FALSE}
## This query can run long
# wqp_orig <- whatWQPsites(bBox = "-127,24,-67,50", countrycode = "US")
# save(wqp_orig, file = './rdata/wqp_orig.RData')
load('./rdata/wqp_orig.RData')
glimpse(wqp_orig)
```

## Filter
Included WQP sites must:

* Be within the continental United States (rough cut to eliminate distant territories)
* Be assigned one of the following Monitoring Location Types: "Lake", "Reservoir", "Riverine Impoundment", "Lake, Reservoir, Impoundment". _These categories were selected in an analysis that assessed how often the sites of each type were located within an NHD polygon and whether they often had Secchi depth measurements, a characteristically limnological sampling parameter. Other location types did sometimes represent desirable samples, but we choose to focus the crosswalk on the most relevant locations rather than conserve all possible links. Stream, wetlands, estuaries and Great Lakes were categorically excluded despite meeting the above criteria in some part._

```{r filter-wqp}
selected_wqp_types <- c('Lake', 'Reservoir', 'Lake, Reservoir, Impoundment', 'Riverine Impoundment')
wqp_filtered <-  wqp_orig %>% 
        filter(LongitudeMeasure < -67 & LongitudeMeasure > -125 & LatitudeMeasure < 50 & LatitudeMeasure > 24) %>%
        filter(MonitoringLocationTypeName %in% selected_wqp_types)
```
The number of WQP sites meeting these criteria is `r nrow(wqp_filtered)`.

## Convert
There is a column in WQP data to indicate the coordinate reference system (CRS). However, not all sites had a value in this column. Prior analysis showed that the most commonly indicated column was NAD83, and so for all sites with an unknown or rare CRS (distant U.S. territories), the NAD83 datum was imputed instead. 

For sites with one of the following other datums, the actual datum specification is preserved: NAD27, WGS84. In order to manage the projections before transforming all the data to a common projection, Albers Equal Area Conic (USGS), we split up the dataset, projected the sites in each datum, converted all rows to Albers USGS, and then reunited all rows at the end.
```{r convert-wqp}
wqp_datums <- wqp_filtered %>% mutate(AssignedCRS = case_when(
        HorizontalCoordinateReferenceSystemDatumName == 'NAD83' ~ 'NAD83',
        HorizontalCoordinateReferenceSystemDatumName == 'NAD27' ~ 'NAD27',
        HorizontalCoordinateReferenceSystemDatumName == 'WGS84' ~ 'WGS84',
        HorizontalCoordinateReferenceSystemDatumName == 'WGS72' ~ 'WGS72',
        TRUE ~ 'NAD83'
))

wqp_nad83 <-  filter(wqp_datums , AssignedCRS == 'NAD83') %>%
              st_as_sf(coords = c("LongitudeMeasure", "LatitudeMeasure")) %>% 
              st_set_crs(NAD83) %>%
              st_transform(ALBERS_USGS)

wqp_nad27 <-  filter(wqp_datums , AssignedCRS == 'NAD27') %>%
              st_as_sf(coords = c("LongitudeMeasure", "LatitudeMeasure")) %>% 
              st_set_crs(NAD27) %>%
              st_transform(ALBERS_USGS)

wqp_wgs84 <-  filter(wqp_datums , AssignedCRS == 'WGS84') %>%
              st_as_sf(coords = c("LongitudeMeasure", "LatitudeMeasure")) %>% 
              st_set_crs(WGS84) %>%
              st_transform(ALBERS_USGS)

# wqp_wgs72 <-  filter(wqp_datums , AssignedCRS == 'WGS72') %>%
#               st_as_sf(coords = c("LongitudeMeasure", "LatitudeMeasure")) %>% 
#               st_set_crs(WGS72) %>%
#               st_transform(ALBERS_USGS)

wqp_sf <- rbind(wqp_nad83, wqp_nad27, wqp_wgs84)

# Cleanup
rm(wqp_nad83, wqp_nad27, wqp_wgs84)
```

## Select
```{r select-wqp}
wqp <- wqp_sf %>%
  select(OrganizationIdentifier, MonitoringLocationIdentifier, MonitoringLocationName, ProviderName, MonitoringLocationTypeName)
```

## Join LAGOS-US
1) WQP sites within a lake polygon are linked to that polygon. Confidence = "high"
```{r join-wqp1, cache = TRUE}
lagos_wqp_0m <- wqp %>%
  st_join(lagos) %>%
  rename(lagoslakeid_0m = lagoslakeid) %>%
  mutate(shared_words_0m  = list_shared_words(GNIS_Name, MonitoringLocationName))
```

Examination of shared words in the names: All lakes where two names are available but don't share words. Some of these lakes have names following some kind of technical form, but others seems to suggest mis-referenced lakes even though the point for the site falls inside the lake. Some examples:
```{r join-wqp2}
weird_matches <- lagos_wqp_0m %>%
  filter(!is.na(GNIS_Name) & !is.na(MonitoringLocationName) & is.na(shared_words_0m))

weird_matches %>%
  sample_n(100) %>%
  st_transform(WGS84) %>%
  leaflet() %>%
  addScaleBar() %>%
  addCircleMarkers(radius = 2, label = ~MonitoringLocationName) %>%
  addWMSTiles(NHD_URL, attribution = USGS_ATTR, options = WMSTileOptions(format = "image/png", transparent = TRUE), layers = "0,1")
```

2) WQP sites can be joined to a lake polygon if they are within 10 meters of it. _Confidence = "medium" if no shared words, "high" if shared words. [not implemented yet]_
```{r join-wqp3, cache = TRUE}
wqp_sites_with_0m_match <- lagos_wqp_0m %>%
  st_set_geometry(NULL) %>%
  filter(!is.na(lagoslakeid_0m)) %>%
  distinct(MonitoringLocationIdentifier)

## Much slower to the point of not working out for me
# lagos_wqp_10m <- wqp %>%
#   anti_join(wqp_sites_with_0m_match, by = "MonitoringLocationIdentifier") %>%
#   st_join(lagos, st_is_within_distance, dist=10)

# Still 6.5 minutes on my machine when I timed it, and more in later runs.
# lagos_10 <- st_buffer(lagos, 10)
# save(lagos_10, file = "./rdata/lagos_10.RData")
load('./rdata/lagos_10.RData')

lagos_wqp_10m <- wqp %>%
  anti_join(wqp_sites_with_0m_match, by = "MonitoringLocationIdentifier") %>%
  st_join(lagos_10) %>%
  rename(lagoslakeid_10m = lagoslakeid) %>%
  mutate(shared_words_10m  = list_shared_words(GNIS_Name, MonitoringLocationName)) %>%
  select(MonitoringLocationIdentifier, lagoslakeid_10m, shared_words_10m)
rm(lagos_10)
```

3) Other sites can be joined if they are within 100 m of a lake polygon, not within an NHDArea StreamRiver feature, and share name words other than "lake", "reservoir", etc. _Confidence = "high" if shared words, "low" if no shared words. [Not implemented, yet]_
```{r join-wqp4, cache = TRUE}
wqp_sites_with_10m_match <- lagos_wqp_10m %>%
  st_set_geometry(NULL) %>%
  filter(!is.na(lagoslakeid_10m)) %>%
  distinct(MonitoringLocationIdentifier) %>%
  union(wqp_sites_with_0m_match)

# # 19 minutes on my machine. Load image instead.
# lagos_100 <- st_buffer(lagos, 100)
# save(lagos_100, file = "./rdata/lagos_10.RData")
load('./rdata/lagos_100.RData')

lagos_wqp_100m <- wqp %>%
  anti_join(wqp_sites_with_10m_match, by = "MonitoringLocationIdentifier") %>%
  st_join(lagos_100) %>%
  rename(lagoslakeid_100m = lagoslakeid) %>%
  mutate(shared_words_100m  = list_shared_words(GNIS_Name, MonitoringLocationName)) %>%
  select(MonitoringLocationIdentifier, lagoslakeid_100m, shared_words_100m)
rm(lagos_100)
```

Join them all up into one and enforce the rules.
```{r join-wqp5}
lagos_wqp_all <- lagos_wqp_0m %>%
  left_join(st_set_geometry(lagos_wqp_10m, NULL), by = "MonitoringLocationIdentifier") %>%
  left_join(st_set_geometry(lagos_wqp_100m, NULL), by = "MonitoringLocationIdentifier") %>%
  mutate(Linked_lagoslakeid = coalesce(lagoslakeid_0m, lagoslakeid_10m),
          Shared_Words = coalesce(shared_words_0m, shared_words_10m)) %>%
  mutate(Linked_lagoslakeid = if_else(!is.na(shared_words_100m), lagoslakeid_100m, Linked_lagoslakeid),
         Shared_Words = coalesce(shared_words_100m, Shared_Words))
```

How many joins were made for each method?
```{r join-wqp6}
n_0 <- lagos_wqp_all %>% filter(!is.na(lagoslakeid_0m)) %>% nrow()
n_10 <- lagos_wqp_all %>% filter(!is.na(lagoslakeid_10m)) %>% nrow()
n_100 <- lagos_wqp_all %>% filter(!is.na(Linked_lagoslakeid) & Linked_lagoslakeid == lagoslakeid_100m) %>% nrow()
```

+**No search distance:** `r n_0`
+**10 m search distance:** `r n_10`
+**100 m search distance (with name condition):** `r n_100`

Some lakes have a very high number of sampling sites. This map shows some examples of lakes with over 50 sampling sites stored.
```{r join-wqp7}
num_pts <- lagos_wqp_0m %>%
  st_set_geometry(NULL) %>%
  filter(!is.na(MonitoringLocationIdentifier)) %>%
  group_by(lagoslakeid_0m, STATE, GNIS_Name) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  arrange(-n)

intense_lakes <- num_pts %>%
  filter(n>50) %>%
  sample_n(5) %>%
  inner_join(st_set_geometry(lagos_wqp_0m, NULL), by = "lagoslakeid_0m") %>%
  inner_join(wqp_sf, by = "MonitoringLocationIdentifier") %>%
  st_as_sf()

mapview(intense_lakes)
```

In `r nrow(distinct(intense_lakes, lagoslakeid))` lakes, there are `r nrow(intense_lakes)` sites.

## Select again
Retain only columns relevant to crosswalk.
```{r select2-wqp}
lagos_wqp <- lagos_wqp_all %>%
  st_set_geometry(NULL) %>%
  select(OrganizationIdentifier, MonitoringLocationIdentifier, MonitoringLocationName, ProviderName, Linked_lagoslakeid)
```

# NHDPlusV2 (value-added National Hydrography Dataset and basis for National Lakes Assessment, LakeCat)
The medium-resolution NHD contains a popular medium-resolution representation of lakes and their hydrographic context. Because the high-resolution NHD data were used to generate LAGOS-US, we must find a connection between the datasets. This connection is the reach code, a 14-digit identifier used to identify each reach as part of a linear referencing system. ReachCodes must sometimes be modified (split, joined, re-assigned, deleted). The NHDReachCrossReference table tracks these changes and shows the new and old ReachCode. 

## Import
The version of the NHDReachCrossReference table that we use has already been filtered to include only the reach codes for lakes and reservoirs in the NHD HR (e.g. streams, wetlands, etc. were removed) to reduce the table size. You could use the full original table with no change to the results.

Glimpse the NHD table.
```{r read-nhd, cache = TRUE}
nhd_plus_orig <- st_read('D:/Not_ContLimno/NHDPlus V2/NHDPlusNationalData/NHDPlusV21_National_Seamless.gdb', 'NHDWaterbody', stringsAsFactors = FALSE) %>%
  mutate(GNIS_ID = as.numeric(GNIS_ID)) # to match the others
glimpse(nhd_plus_orig)
```

Glimpse the NHDReachCrossReference table.
```{r}
## In order to read table with OpenFileGDB, need sf from Github > 2018-02-11 since this commit
## https://github.com/r-spatial/sf/commit/77a31f2989a1d217438fb629ac34d7ef31baa9c2
## or sf > 0.6-1 on CRAN to be released March 2018
# nhd_xref <- st_read('D:/Continental_Limnology/Data_Working/LAGOS_US_Predecessors.gdb', 'NHDReachCrossReference_lakes') %>%
#   select(OldReachCode, OldReachDate, NewReachCode, NewReachDate)
# save(nhd_xref, file = './rdata/nhd_xref.RData')
load('./rdata/nhd_xref.RData')

glimpse(nhd_xref)
```

## Filter
We can't use the join method to connect to any NHDPlusV2 lakes that don't have REACHCODE populated. We will revisit these lakes along with others that won't connect later.
```{r filter-nhd}
nhd_plus_filtered <- nhd_plus_orig %>%
  filter(REACHCODE != ' ')

# This bit is orphaned for now unless we make a third connection attempt
# nhd_plus_alt_filtered <- nhd_plus_orig
```

## Convert
These data are already spatial polygons and we want a dataset with no geometry instead.
```{r convert-nhd}
nhd_plus_df <- nhd_plus_filtered %>%
  st_set_geometry(NULL)
```

## Select
```{r select-nhd}
nhd_plus <- nhd_plus_df %>%
  select(COMID, FDATE, GNIS_ID, GNIS_NAME, REACHCODE, AREASQKM)
```

## Join LAGOS-US
This join creates many:many relationships. A scant few ReachCodes in the LAGOS-US population are associated with two Permanent_Identifiers before the join. Most reach codes don't have an entry in the cross reference table, suggesting that lakes still holding their original reach code should have the same reach code in any version of the NHD.

```{r join-nhd1}
# Join to NHDReachCrossReference (nhd_xref)
lagos_nhdx <- lagos_df %>%
  filter(!is.na(ReachCode)) %>%
  left_join(nhd_xref, by = c("ReachCode" = "NewReachCode"))
  #mutate(has_xref = if_else(!is.na(OldReachCode), 'Y', 'N'))

no_xref <- lagos_df %>%
  filter(!is.na(ReachCode)) %>%
  anti_join(nhd_xref, by = c("ReachCode" = "NewReachCode")) %>%
  nrow()

new_reach_only <- lagos_nhdx %>%
  filter(is.na(OldReachCode)) %>%
  nrow()
```

`r new_reach_only` reach codes have only a new reach code in NHDReachCrossReference and the OldReachCode is missing. In other words, about `r round(100*new_reach_only/nrow(lagos_df), 2)`% of LAGOS-US lakes have never changed reach codes. About a tenth of the lakes have no entry in NHDReachCrossReference, suggesting this table is usually but not always populated when new reach codes are assigned.

```{r join-nhd2}
# Join on old reach codes
lagos_nhd_1 <- lagos_nhdx %>%
  filter(!is.na(OldReachCode)) %>%
  left_join(nhd_plus, by = c("OldReachCode" = "REACHCODE"), suffix = c("_HR", "_MR"))

# Join on new reach codes (about a dozen lakes will link in both these queries)
lagos_nhd_2 <- lagos_df %>%
  mutate(OldReachCode = ReachCode) %>% # tinkering for upcoming union
  filter(!is.na(ReachCode)) %>%
  left_join(nhd_plus, by = c("ReachCode" = "REACHCODE"), suffix = c("_HR", "_MR"))

lagos_nhd_all <- lagos_nhd_1 %>%
  select(-OldReachDate, -NewReachDate) %>%
  union(lagos_nhd_2)
```

Numerous lakes aren't able to be connected between the NHDPlusV2 and the NHD HR. The HR contains more small lakes, so let's look for a minute only at lakes over 10 hectares.
```{r join-nhd3}
# examples[1]: Simply no connection between codes. Former code is 01090001031010.
# examples[2]: One lake to three. First lake keeps reach code, other two aren't linked (01090003000918, 01090003008076)
# examples[3]: Three lakes to one. New code entered as unlinked. Old three codes never appear in the table. Those codes are
# 02030104000470, 02030104000473, 02030104000468
examples <- c('01090001001634', '01090003008075', '02030104005251')

no_link <- lagos_nhd_all %>%
  filter(AreaSqKm >= .1) %>%
  group_by(lagoslakeid, ReachCode) %>%
  summarize(n = n_distinct(COMID, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(n < 1)

no_link_all <- lagos_nhd_all %>%
  # same as above except this filter step
  group_by(lagoslakeid, ReachCode) %>%
  summarize(n = n_distinct(COMID, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(n < 1)

nhd_xref %>%
  filter(OldReachCode %in% examples | NewReachCode %in% examples)
```

For those lakes that didn't link between NHD versions, try linking them through GNIS IDs.
```{r join-nhd4}
nhd_gnis_nhd <- lagos_df %>%
  inner_join(no_link_all) %>%
  filter(!is.na(GNIS_ID)) %>%
  inner_join(nhd_plus, by = c("GNIS_ID" = "GNIS_ID"))
```
It works. `r nrow(nhd_gnis_nhd)` lakes that couldn't be linked with NHDReachCrossReference can be linked with the GNIS_ID value.

## Select again
```{r select2-nhd}
lagos_nhd_not_missing <- lagos_nhd_all %>%
  filter(!is.na(COMID))

lagos_nhd <- lagos_df %>%
  left_join(lagos_nhd_not_missing, by = "lagoslakeid") %>% # removes OldReachCodes that don't link but keeps all lakes
  left_join(nhd_gnis_nhd, by = "lagoslakeid") %>%
  mutate(NHDPlusv2_COMID = coalesce(COMID.x, COMID.y)) %>%
  mutate(NHDPlusv2_ReachCode = coalesce(OldReachCode, REACHCODE)) %>%
  mutate(NHDPlusv2_GNIS_Name = coalesce(GNIS_NAME.x, GNIS_NAME.y)) %>% #all-caps is medium res
  mutate(NHDPlusv2_AreaSqKm = coalesce(AREASQKM.x, AREASQKM.y)) %>%
  select(lagoslakeid, NHDPlusv2_COMID, NHDPlusv2_ReachCode, NHDPlusv2_GNIS_Name, NHDPlusv2_AreaSqKm)
```

# LAGOS-NE
_[add introduction here]_
This dataset can be downloaded and unzipped from _[fill in EDI web link here and possibly set up the below so it downloads, truly]_
When the LAGOS-US lagoslakeid values were generated, they were joined on Permanent_Identifier to the LAGOS-NE, so most of the lagoslakeid values should not have changed. Nonetheless, some could not be connected this way.

## Import
Glimpse the original LAGOS-NE dataset.
```{r read-ne, cache=TRUE}
# lagosNE_orig <- st_read('C:/Users/smithn78/Dropbox/CSI/CSI_LAGOS-exports/LAGOS-NE-EDI/LAGOS-NE-GIS/FileGDB/LAGOS_NE_GIS_Data_v1.0.gdb', 'LAGOS_NE_All_Lakes_1ha') %>%
#   st_zm(drop=TRUE) %>%
#   mutate(GNIS_ID = as.numeric(GNIS_ID)) %>%
#   st_transform(ALBERS_USGS) # no actual change, just proj4string housekeeping.
# save(lagosNE_orig, file = './rdata/lagosNE_orig.RData')
load('./rdata/lagosNE_orig.RData')
glimpse(lagosNE_orig)
```

## Filter
No need to filter. These lakes had essentially the same criteria for inclusion as LAGO-US, above, except that they were confined to a 17-state region in the northeast U.S.

## Convert and select
```{r convert-ne}
lagosNE <- lagosNE_orig %>%
  select(LAGOSNE_lagoslakeid = lagoslakeid, LAGOSNE_PermanentIdentifier = Permanent_Identifier, LAGOSNE_ReachCode = ReachCode, GNIS_ID, GNIS_Name) %>%
  st_set_geometry(NULL)
```

## Join LAGOS-US
Unlike with NHDPlusV2, these two datasets shared the identifier Permanent_Identifier and we will try to join lakes on that column first. The subsequent two joins parallel the joins with NHDPlusV2, above. We will reuse the lagos_nhdx table.
```{r join-ne0}
lagos_lagosNE_0 <- lagos_df %>%
  inner_join(lagosNE, by = c("Permanent_Identifier" = "LAGOSNE_PermanentIdentifier"), suffix = c("_US", "_NE")) %>%
  rename(OldReachCode = LAGOSNE_ReachCode) %>%
  mutate(LAGOSNE_PermanentIdentifier = Permanent_Identifier)

```


```{r join-ne1}
lagos_lagosNE_1 <- lagos_nhdx %>%
  filter(!is.na(OldReachCode)) %>%
  left_join(lagosNE, by = c("OldReachCode" = "LAGOSNE_ReachCode"), suffix = c("_US", "_NE"))

# Join on new reach codes (about a dozen lakes will link in both these queries)
lagos_lagosNE_2 <- lagos_df %>%
  mutate(OldReachCode = ReachCode) %>% # tinkering for upcoming union
  filter(!is.na(ReachCode)) %>%
  left_join(lagosNE, by = c("ReachCode" = "LAGOSNE_ReachCode"), suffix = c("_US", "_NE"))

lagos_lagosNE_all <- lagos_lagosNE_1 %>%
  select(-OldReachDate, -NewReachDate) %>%
  union(lagos_lagosNE_2) %>% 
  union(lagos_lagosNE_0)

lagos_lagosNE_all %>% filter(lagoslakeid == 583)
```

After trying the code below, it seems upon further observation that the GNIS_ID values in LAGOS-NE have no relation to the latest GNIS_ID values. 
```{r join-ne2}
# no_link_lagosNE <- lagos_lagosNE_all %>%
#   group_by(lagoslakeid, ReachCode) %>%
#   summarize(n = n_distinct(LAGOSNE_lagoslakeid, na.rm = TRUE)) %>%
#   ungroup() %>%
#   filter(n < 1)
# 
# lagosUS_gnis_lagosNE <- lagos_df %>%
#   inner_join(no_link_lagosNE) %>%
#   filter(!is.na(GNIS_ID)) %>%
#   inner_join(lagosNE, by = c("GNIS_ID" = "GNIS_ID"))
```


## Select again
```{r select2-ne}
lagosUS_lagosNE <- lagos_lagosNE_all %>%
  filter(!is.na(LAGOSNE_lagoslakeid)) %>%
  arrange(lagoslakeid)
```

# NLA (US EPA National Lakes Assessment)
The lakes in the NLA are identified with their NHDPlus COMID and ReachCode. It should be simple to add them to the crosswalk by doing a 1:1 join with the NHDPlusV2 COMID.

## Import
Import the two NLA files. It seems that the 2012 file already manages the link between the 2012 sites back to the 2007 sites.
```{r}
nla2007_orig <- read_csv('https://www.epa.gov/sites/production/files/2014-01/nla2007_sampledlakeinformation_20091113.csv',
                         col_types = cols(REACHCODE = col_character()))
nla2012_orig <- read_csv('https://www.epa.gov/sites/production/files/2016-12/nla2012_wide_siteinfo_08232016.csv',
                         col_types = cols(RCHCODE = col_character(),
                                          NESLAKE_ID = col_character())) # unimportant but avoid import error))

glimpse(nla2012_orig, width = 100)
?glimpse
```

Unfortunately, the RCHCODE values in the 2012 data that can be downloaded online were exported improperly, using scientific notation that cuts off the very important final digits. For example:
```{r}
nla2012_orig %>% select(RCHCODE) %>% sample_n(10)
```
With luck, we can work around this issue.

<!---This no longer seems necessary: Import the NHDPlus V1-to-V2 crosswalk.--->
```{r}
# # # Code for reproducibility, requires devtools and package "archive" on Github
# # if(!require("archive)")) {
# #   if(!require("devtools")) install.packages("devtools")
# #   devtools::install_github("jimhester/archive")
# # }
# # if(!require("foreign")) install.packages("foreign")
# # tf <- tempfile()
# # download.file('http://www.horizon-systems.com/NHDPlusData/NHDPlusV21/Data/NationalData/NHDPlusV21_NationalData_V1_To_V2_Crosswalk_01.7z', tf, mode = 'wb')
# # dbf_path <- archive::archive_extract(tf, '.', 'NHDPlusV1Network_V2Network_Crosswalk.dbf')$path[1]
# # v1_v2_xwalk <- foreign::read.dbf(dbf_path[1])
# # unlink(tf)
# # save(v1_v2_xwalk, file = './rdata/v1_v2_xwalk.RData')
# load('./rdata/v1_v2_xwalk.RData')
# glimpse(v1_v2_xwalk)
```

## Filter
No need.

## Convert
No need.

## Select
```{r}
nla2007 <- nla2007_orig %>%
  distinct(SITE_ID, REACHCODE, COM_ID)

nla2012 <- nla2012_orig %>%
  distinct(SITE_ID, SITEID_07, COMID2012, COMID2007, COMIDS2007, GNIS_ID, GNIS_NAME, NESSTORET)
```

## Join to LAGOS_US via NHDPlusV2 via the V1-to-V2 crosswalk.
We will use the nla2012 table as the left table in the join and also join through the original nhd_plus dataset so that we can produce a list of NLA lakes that could not be linked to a lagoslakeid. The NLA lakes that don't link will be assigned a lagoslakeid through our manual linking process (that starts with a spatial link).
```{r}
nla2012_lagos_join <- nla2012 %>%
  left_join(nhd_plus, by = c("COMID2012" = "COMID")) %>%
  left_join(lagos_nhd, by = c("COMID2012" = "NHDPlusv2_COMID"))
```

Check on how many lakes didn't link through each step.
```{r}
n_nla_nhd <- nla2012_lagos_join %>%
  filter(is.na(REACHCODE)) %>%
  distinct(SITE_ID) %>%
  nrow()
n_nla_lagos <- nla2012_lagos_join %>%
  filter(is.na(lagoslakeid)) %>%
  distinct(SITE_ID) %>%
  nrow()
```
`r n_nla_nhd` lakes out of `r nrow(nla2012)` NLA lakes cannot be linked to the NHDPlusV2. We did try the V1-to-V2 crosswalk and were not able to make any additional links. Far more lakes are unable to be linked to a lagoslakeid: `r n_nla_lagos`. This is due to the poor match between the NHDPlusV2 and the LAGOS Lake population. If we improve that link, these numbers will increase. This work is proposed.

## Select again
```{r}
nla2012_lagos <- nla2012_lagos_join %>%
  select(
    NLA2012_SITE_ID = SITE_ID,
    NLA2007_SITE_ID = SITEID_07,
    lagoslakeid
  )
```


# Final, single crosswalk table

```{r final}
# start with lagos based stuff
together <- lagos_gnis %>%
  inner_join(lagos_centroid, by = "lagoslakeid") %>%
  left_join(lagos_wqp, by = c("lagoslakeid" = "Linked_lagoslakeid")) %>%
  left_join(lagos_nhd, by = "lagoslakeid") %>%
  left_join(lagosUS_lagosNE, by = "lagoslakeid") %>%
  left_join(nla2012_lagos, by = "lagoslakeid")



counts_round1 <- together %>%
  group_by(lagoslakeid) %>%
  summarize(count_wqp_per_lagos_id = n_distinct(MonitoringLocationIdentifier, na.rm = TRUE), 
            count_nhdplusv2_per_lagos_id = n_distinct(NHDPlusv2_COMID, na.rm = TRUE),
            count_lagosNE_per_lagos_id = n_distinct(LAGOSNE_lagoslakeid, na.rm = TRUE)) %>%
  right_join(together, by = "lagoslakeid")

counts_round2 <- counts_round1 %>%
  filter(!is.na(NHDPlusv2_COMID)) %>%
  group_by(NHDPlusv2_COMID) %>%
  summarize(count_lagos_per_nhdplusv2_id = n_distinct(lagoslakeid, na.rm = TRUE))%>%
  right_join(counts_round1, by = "NHDPlusv2_COMID")

counts_round3 <- counts_round2 %>%
  filter(!is.na(LAGOSNE_lagoslakeid)) %>%
  group_by(LAGOSNE_lagoslakeid) %>%
  summarize(count_lagos_per_lagosNE_id = n_distinct(lagoslakeid, na.rm = TRUE))%>%
  right_join(counts_round2, by = "LAGOSNE_lagoslakeid")

final <- counts_round3 %>%
  select(
    lagoslakeid,
    NHDHR_PermanentIdentifier = Permanent_Identifier.x,
    NHDHR_ReachCode = ReachCode.x,
    NHDHR_AreaSqKm = AreaSqKm.x,
    GNIS_ID,
    GNIS_Name,
    LAGOS_LakeName,
    LAGOS_CountyName,
    LAGOS_CountyFIPS,
    LAGOS_LatitudeNAD83,
    LAGOS_LongitudeNAD83,
    State = STATE.x,
    WQP_MonitoringLocationIdentifier = MonitoringLocationIdentifier,
    WQP_MonitoringLocationName = MonitoringLocationName,
    WQP_ProviderName = ProviderName,
    NHDPlusv2_COMID,
    NHDPlusv2_ReachCode,
    NHDPlusv2_AreaSqKm,
    LAGOSNE_lagoslakeid,
    NLA2007_SITE_ID,
    NLA2012_SITE_ID,
    count_wqp_per_lagos_id,
    count_nhdplusv2_per_lagos_id,
    count_lagos_per_nhdplusv2_id,
    count_lagosNE_per_lagos_id,
    count_lagos_per_lagosNE_id
  )
```

Glimpse at the final table.
```{r}
glimpse(final)
```

An example of a  group of lakes in the final table.
```{r}
final %>% filter(lagoslakeid %in% c(10,9,33099))

final %>% filter(lagoslakeid == 583)
```


Write out the final product.
```{r write-final}
write_csv(final, 'LAGOS_Lake_Link.csv')
```

# List of to-dos and ideas to make more or better connections
<!---Add more explanatory text. Problem/solution format & evaluate difficulty.--->

A) PROBLEM: Almost 25% of lakes cannot be linked to their NHDPlusv2 identifier (and therefore their StreamCat/LakeCat identifier). SOLUTION: Link differing NHD version lakes through spatial analysis. This is the highest impact suggestion.
B) PROBLEM: There are still many unlinked WQP sites and some of them do link easily if adequate rules are proposed, but introduce a higher possibility of creating incorrect links for other similar sites. SOLUTION: We could make more links to WQP sites if we added a way to indicate "low confidence" links. For instance: we could add more sites that are within 100 m but have no name match.
C) PROBLEM: Some applications ask users to specify the lake they're at when the user does not have GPS (Ewing and others harmful algal bloom app). SOLUTION: Add "nearest municipality" using TIGER data and a "closest" spatial join. (Discussed previously with Holly Ewing and was identified as desirable at this time, but cut from this draft for time.)
D) Manual links for LAGOS-NE lakes that have limno data (26 lakes) but that can't be found through the Permanent_Identifier or reach code in LAGOS-US. (In progress)
F) Manual links for any NLA sites that still don't connect if we add the spatial analysis in TO-DO item (B).
H) Merge NHDPlusV2 names into the semi-colon list (cut for time--needs another join/distinct/verbose name calculation chunk)

# Things that can't be done with the crosswalk
These items can be described as designed limitations because this lake identifier crosswalk is designed primarily to work with LAGOS. Or--if there is enough interest from the preview group--we can consider adding these capabilities.
+ A user cannot find identifiers pertaining to a lake that isn't in LAGOS-US. SOLUTION: Use outer joins and allow the crosswalk to grow a fair amount in size to allow NULLs in any of the identifiers. Revise the documentation to reflect the expansion.
+ A user cannot connect WQP sites to the NHDPlusV2 representation of lakes. Example: 2 NHDPlusV2 lakes to 1 LAGOS-US lake. SOLUTION: Refine the entity-relationship model to join between the WQP and NHDPlusV2 directly. Rework subsequent joins in the script to accomodate the change. This change probably won't affect the overall size or usability of the crosswalk too much.